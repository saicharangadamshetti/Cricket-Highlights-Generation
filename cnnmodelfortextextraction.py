# -*- coding: utf-8 -*-
"""CnnModelForTextExtraction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MuOSlKXKUmNcX7xcIUFTApQ4ToP3HIBG
"""

from keras.datasets import mnist
from keras.utils import to_categorical
from google.colab.patches import cv2_imshow
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation
from keras.layers.convolutional import Conv2D, MaxPooling2D
import joblib

def data_load_and_preprocess():
  (X_train, y_train), (X_test, y_test) = mnist.load_data()
  img_rows=28
  img_cols=28
  X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)
  X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)
  input_shape = (img_rows, img_cols, 1)
  X_train = X_train.astype('float32')
  X_test = X_test.astype('float32')
  X_train /= 255
  X_test /= 255
  print('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)
  #set number of categories
  num_category = 10
  # convert class vectors to binary class matrices
  y_train = to_categorical(y_train, num_category)
  y_test = to_categorical(y_test, num_category)

## Declare the model
def build_model():
  model = Sequential()

  ## Declare the layers
  layer_1 = Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1))
  layer_2 = Conv2D(64, kernel_size=3, activation='relu')
  layer_3 = Flatten()
  layer_4 = Dense(10, activation='softmax')

  ## Add the layers to the model
  model.add(layer_1)
  model.add(layer_2)
  model.add(layer_3)
  model.add(layer_4)
  return model

if __name__ == '__main__':
  data_load_and_preprocess()
  build_model()
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
  model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3,batch_size=32)
  score = model.evaluate(X_test, y_test, verbose=0)
  print('Test loss:', score[0]) #Test loss: 0.0296396646054
  print('Test accuracy:', score[1]) #Test accuracy: 0.9904
  model.summary()
  filename = 'drive/My Drive/Processedvideo/scoreboardExtractionmodel.sav'
  joblib.dump(model, filename)